{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started submitting EXPORT_PDF job\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting job result\n",
      "ERROR:root:Exception encountered while executing operation: description =Thread interrupted while waiting for operation execution status!!, requestTrackingId=None\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\adobe\\pdfservices\\operation\\internal\\pdf_services_helper.py\", line 145, in get_job_result\n",
      "    time.sleep(retry_after)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\austi\\AppData\\Local\\Temp\\ipykernel_23684\\3861851520.py\", line 46, in __init__\n",
      "    pdf_services_response = pdf_services.get_job_result(location, ExportPDFResult)\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\adobe\\pdfservices\\operation\\internal\\util\\enforce_types.py\", line 37, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\adobe\\pdfservices\\operation\\pdf_services.py\", line 101, in get_job_result\n",
      "    return PDFServicesHelper.get_job_result(self.__executionContext, polling_url, result_type)\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\adobe\\pdfservices\\operation\\internal\\pdf_services_helper.py\", line 147, in get_job_result\n",
      "    raise SdkException(\"Thread interrupted while waiting for operation execution status!!\")\n",
      "adobe.pdfservices.operation.exception.exceptions.SdkException: description =Thread interrupted while waiting for operation execution status!!, requestTrackingId=None\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from adobe.pdfservices.operation.auth.service_principal_credentials import ServicePrincipalCredentials\n",
    "from adobe.pdfservices.operation.exception.exceptions import ServiceApiException, ServiceUsageException, SdkException\n",
    "from adobe.pdfservices.operation.io.cloud_asset import CloudAsset\n",
    "from adobe.pdfservices.operation.io.stream_asset import StreamAsset\n",
    "from adobe.pdfservices.operation.pdf_services import PDFServices\n",
    "from adobe.pdfservices.operation.pdf_services_media_type import PDFServicesMediaType\n",
    "from adobe.pdfservices.operation.pdfjobs.jobs.export_pdf_job import ExportPDFJob\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_params import ExportPDFParams\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_target_format import ExportPDFTargetFormat\n",
    "from adobe.pdfservices.operation.pdfjobs.result.export_pdf_result import ExportPDFResult\n",
    "\n",
    "# Initialize the logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class ExportPDFToDOCX:\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            file = open('./test.pdf', 'rb')\n",
    "            input_stream = file.read()\n",
    "            file.close()\n",
    "\n",
    "            # Initial setup, create credentials instance\n",
    "            credentials = ServicePrincipalCredentials(\n",
    "                client_id=os.getenv('PDF_SERVICES_CLIENT_ID'),\n",
    "                client_secret=os.getenv('PDF_SERVICES_CLIENT_SECRET')\n",
    "            )\n",
    "\n",
    "            # Creates a PDF Services instance\n",
    "            pdf_services = PDFServices(credentials=credentials)\n",
    "\n",
    "            # Creates an asset(s) from source file(s) and upload\n",
    "            input_asset = pdf_services.upload(input_stream=input_stream, mime_type=PDFServicesMediaType.PDF)\n",
    "\n",
    "            # Create parameters for the job\n",
    "            export_pdf_params = ExportPDFParams(target_format=ExportPDFTargetFormat.DOCX)\n",
    "\n",
    "            # Creates a new job instance\n",
    "            export_pdf_job = ExportPDFJob(input_asset=input_asset, export_pdf_params=export_pdf_params)\n",
    "\n",
    "            # Submit the job and gets the job result\n",
    "            location = pdf_services.submit(export_pdf_job)\n",
    "            pdf_services_response = pdf_services.get_job_result(location, ExportPDFResult)\n",
    "\n",
    "            # Get content from the resulting asset(s)\n",
    "            result_asset: CloudAsset = pdf_services_response.get_result().get_asset()\n",
    "            stream_asset: StreamAsset = pdf_services.get_content(result_asset)\n",
    "\n",
    "            # Creates an output stream and copy stream asset's content to it\n",
    "            output_file_path = './test.docx'\n",
    "            with open(output_file_path, \"wb\") as file:\n",
    "                file.write(stream_asset.get_input_stream())\n",
    "\n",
    "        except (ServiceApiException, ServiceUsageException, SdkException) as e:\n",
    "            logging.exception(f'Exception encountered while executing operation: {e}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ExportPDFToDOCX()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7867/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7867/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started submitting EXPORT_PDF job\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished polling for status\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting content\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting content\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\queueing.py\", line 622, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\blocks.py\", line 2016, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\blocks.py\", line 1569, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\anyio\\_backends\\_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\austi\\AppData\\Local\\Temp\\ipykernel_26020\\2476519689.py\", line 128, in process_pdf\n",
      "    docx_file = exporter.process()\n",
      "AttributeError: 'ExportPDFToDOCX' object has no attribute 'process'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, BertTokenizerFast, BertForSequenceClassification\n",
    "\n",
    "from adobe.pdfservices.operation.auth.service_principal_credentials import ServicePrincipalCredentials\n",
    "from adobe.pdfservices.operation.exception.exceptions import ServiceApiException, ServiceUsageException, SdkException\n",
    "from adobe.pdfservices.operation.io.cloud_asset import CloudAsset\n",
    "from adobe.pdfservices.operation.io.stream_asset import StreamAsset\n",
    "from adobe.pdfservices.operation.pdf_services import PDFServices\n",
    "from adobe.pdfservices.operation.pdf_services_media_type import PDFServicesMediaType\n",
    "from adobe.pdfservices.operation.pdfjobs.jobs.export_pdf_job import ExportPDFJob\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_params import ExportPDFParams\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_target_format import ExportPDFTargetFormat\n",
    "from adobe.pdfservices.operation.pdfjobs.result.export_pdf_result import ExportPDFResult\n",
    "\n",
    "# Initialize the logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class ExportPDFToDOCX:\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            file = open('./test.pdf', 'rb')\n",
    "            input_stream = file.read()\n",
    "            file.close()\n",
    "\n",
    "            # Initial setup, create credentials instance\n",
    "            credentials = ServicePrincipalCredentials(\n",
    "                client_id=os.getenv('PDF_SERVICES_CLIENT_ID'),\n",
    "                client_secret=os.getenv('PDF_SERVICES_CLIENT_SECRET')\n",
    "            )\n",
    "\n",
    "            # Creates a PDF Services instance\n",
    "            pdf_services = PDFServices(credentials=credentials)\n",
    "\n",
    "            # Creates an asset(s) from source file(s) and upload\n",
    "            input_asset = pdf_services.upload(input_stream=input_stream, mime_type=PDFServicesMediaType.PDF)\n",
    "\n",
    "            # Create parameters for the job\n",
    "            export_pdf_params = ExportPDFParams(target_format=ExportPDFTargetFormat.DOCX)\n",
    "\n",
    "            # Creates a new job instance\n",
    "            export_pdf_job = ExportPDFJob(input_asset=input_asset, export_pdf_params=export_pdf_params)\n",
    "\n",
    "            # Submit the job and gets the job result\n",
    "            location = pdf_services.submit(export_pdf_job)\n",
    "            pdf_services_response = pdf_services.get_job_result(location, ExportPDFResult)\n",
    "\n",
    "            # Get content from the resulting asset(s)\n",
    "            result_asset: CloudAsset = pdf_services_response.get_result().get_asset()\n",
    "            stream_asset: StreamAsset = pdf_services.get_content(result_asset)\n",
    "\n",
    "            # Creates an output stream and copy stream asset's content to it\n",
    "            output_file_path = './test.docx'\n",
    "            with open(output_file_path, \"wb\") as file:\n",
    "                file.write(stream_asset.get_input_stream())\n",
    "\n",
    "        except (ServiceApiException, ServiceUsageException, SdkException) as e:\n",
    "            logging.exception(f'Exception encountered while executing operation: {e}')\n",
    "\n",
    "    def convert_pdf_to_docx(self):\n",
    "        try:\n",
    "            # Existing code for opening the PDF file, reading content, and creating credentials\n",
    "            # ...\n",
    "\n",
    "            # Create parameters for the job, ensuring target format is DOCX\n",
    "            export_pdf_params = ExportPDFParams(target_format=ExportPDFTargetFormat.DOCX)\n",
    "\n",
    "            # Create a new job instance with the input asset and export parameters\n",
    "            export_pdf_job = ExportPDFJob(input_asset=input_asset, export_pdf_params=export_pdf_params)\n",
    "\n",
    "            # Submit the job and retrieve the result\n",
    "            location = pdf_services.submit(export_pdf_job)\n",
    "            pdf_services_response = pdf_services.get_job_result(location, ExportPDFResult)\n",
    "\n",
    "            # Get content from the resulting asset and write it to a temporary DOCX file\n",
    "            result_asset: CloudAsset = pdf_services_response.get_result().get_asset()\n",
    "            stream_asset: StreamAsset = pdf_services.get_content(result_asset)\n",
    "\n",
    "            # Create a temporary filename for the DOCX (ensure valid and accessible path)\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".docx\", delete=False) as temp_file:\n",
    "                temp_file_path = temp_file.name\n",
    "                with open(temp_file_path, \"wb\") as file:\n",
    "                    file.write(stream_asset.get_input_stream())\n",
    "\n",
    "            # Return the temporary DOCX file path\n",
    "            return temp_file_path\n",
    "\n",
    "        except (ServiceApiException, ServiceUsageException, SdkException) as e:\n",
    "            logging.exception(f'Exception encountered while converting PDF: {e}')\n",
    "            return None  # Indicate failure by returning None\n",
    "\n",
    "def clean_text_with_bert(text):\n",
    "    # Load pre-trained BERT model and tokenizer\n",
    "    model_name = \"bert-base-uncased\"  # You can change this to a different BERT model\n",
    "    model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "    # Prepare the input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    # Get model output\n",
    "    outputs = model(**inputs)\n",
    "    predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "    # Based on the predicted label, perform appropriate cleaning\n",
    "    if predicted_label == 0:  # Assuming label 0 corresponds to \"clean\" text\n",
    "        cleaned_text = text\n",
    "    else:\n",
    "        # Perform cleaning based on the predicted label (e.g., noise removal, spelling correction)\n",
    "        # You can customize this logic based on your specific requirements\n",
    "        cleaned_text = perform_cleaning(text)  # Replace with your cleaning function\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def perform_cleaning(text):\n",
    "    # Example cleaning logic: remove stop words and punctuation\n",
    "    stop_words = set([\"the\", \"and\", \"in\", \"of\", \"to\", \"for\", \"with\", \"that\", \"it\", \"is\", \"as\", \"this\", \"be\", \"have\", \"not\", \"but\", \"by\", \"from\", \"at\", \"on\", \"or\", \"are\"])\n",
    "    cleaned_text = \" \".join([word for word in text.split() if word not in stop_words and word.isalnum()])\n",
    "    return cleaned_text\n",
    "\n",
    "def process_pdf(pdf_file):\n",
    "    # Convert PDF to DOCX\n",
    "    exporter = ExportPDFToDOCX()\n",
    "    docx_file = exporter.process()\n",
    "\n",
    "    if docx_file is None:\n",
    "        return \"Error occurred during PDF to DOCX conversion.\"\n",
    "\n",
    "    # Read DOCX content\n",
    "    import docx2txt\n",
    "    text = docx2txt.process(docx_file)\n",
    "\n",
    "    # Clean text using BERT\n",
    "    cleaned_text = clean_text_with_bert(text)\n",
    "\n",
    "    # Clean up the temporary DOCX file (optional)\n",
    "    # os.remove(docx_file)  # Uncomment if you want to delete the temporary file\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_pdf,\n",
    "    inputs=gr.File(label=\"Upload PDF\"),\n",
    "    outputs=gr.Textbox(label=\"Cleaned Document\"),\n",
    "    title=\"PDF Cleaner\",\n",
    "    description=\"Upload a PDF file to convert it to DOCX and clean the text using BERT.\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gradio in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (5.0.1)\n",
      "Requirement already satisfied: torch in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (1.13.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (4.24.0)\n",
      "Requirement already satisfied: pdfservices-sdk in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (4.0.0)\n",
      "Requirement already satisfied: docx2txt in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (0.8)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (4.6.2.post1)\n",
      "Requirement already satisfied: fastapi<1.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (0.112.2)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.4.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (1.4.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (0.25.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (3.10.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (2.9.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (0.6.2)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (0.12.5)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (0.30.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio-client==1.4.0->gradio) (2024.5.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from gradio-client==1.4.0->gradio) (11.0.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: setuptools~=69.5.1 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from pdfservices-sdk) (69.5.1)\n",
      "Requirement already satisfied: sphinx~=7.3.7 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from pdfservices-sdk) (7.3.7)\n",
      "Requirement already satisfied: sphinx-rtd-theme~=2.0.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from pdfservices-sdk) (2.0.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from fastapi<1.0->gradio) (0.38.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from sphinx~=7.3.7->pdfservices-sdk) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from sphinx~=7.3.7->pdfservices-sdk) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from sphinx~=7.3.7->pdfservices-sdk) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from sphinx~=7.3.7->pdfservices-sdk) (2.1.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from sphinx~=7.3.7->pdfservices-sdk) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from sphinx~=7.3.7->pdfservices-sdk) (2.0.0)\n",
      "Requirement already satisfied: Pygments>=2.14 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from sphinx~=7.3.7->pdfservices-sdk) (2.18.0)\n",
      "Requirement already satisfied: docutils<0.22,>=0.18.1 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from sphinx~=7.3.7->pdfservices-sdk) (0.20.1)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from sphinx~=7.3.7->pdfservices-sdk) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.9 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from sphinx~=7.3.7->pdfservices-sdk) (2.16.0)\n",
      "Requirement already satisfied: alabaster~=0.7.14 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from sphinx~=7.3.7->pdfservices-sdk) (0.7.16)\n",
      "Requirement already satisfied: imagesize>=1.3 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from sphinx~=7.3.7->pdfservices-sdk) (1.4.1)\n",
      "Requirement already satisfied: tomli>=2 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from sphinx~=7.3.7->pdfservices-sdk) (2.0.2)\n",
      "Requirement already satisfied: colorama>=0.4.5 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from sphinx~=7.3.7->pdfservices-sdk) (0.4.6)\n",
      "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from sphinx-rtd-theme~=2.0.0->pdfservices-sdk) (4.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from typer<1.0,>=0.12->gradio) (13.8.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\austi\\appdata\\roaming\\python\\python310\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio torch transformers pdfservices-sdk docx2txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7871/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7871/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started submitting EXPORT_PDF job\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished polling for status\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting content\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting content\n",
      "C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "\n",
    "from adobe.pdfservices.operation.auth.service_principal_credentials import ServicePrincipalCredentials\n",
    "from adobe.pdfservices.operation.exception.exceptions import ServiceApiException, ServiceUsageException, SdkException\n",
    "from adobe.pdfservices.operation.io.cloud_asset import CloudAsset\n",
    "from adobe.pdfservices.operation.io.stream_asset import StreamAsset\n",
    "from adobe.pdfservices.operation.pdf_services import PDFServices\n",
    "from adobe.pdfservices.operation.pdf_services_media_type import PDFServicesMediaType\n",
    "from adobe.pdfservices.operation.pdfjobs.jobs.export_pdf_job import ExportPDFJob\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_params import ExportPDFParams\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_target_format import ExportPDFTargetFormat\n",
    "from adobe.pdfservices.operation.pdfjobs.result.export_pdf_result import ExportPDFResult\n",
    "\n",
    "# Initialize the logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class ExportPDFToDOCX:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.credentials = ServicePrincipalCredentials(\n",
    "            client_id=os.getenv('PDF_SERVICES_CLIENT_ID'),\n",
    "            client_secret=os.getenv('PDF_SERVICES_CLIENT_SECRET')\n",
    "        )\n",
    "        self.pdf_services = PDFServices(credentials=self.credentials)\n",
    "\n",
    "    def process(self):\n",
    "        try:\n",
    "            with open(self.pdf_path, 'rb') as file:\n",
    "                input_stream = file.read()\n",
    "\n",
    "            input_asset = self.pdf_services.upload(input_stream=input_stream, mime_type=PDFServicesMediaType.PDF)\n",
    "            export_pdf_params = ExportPDFParams(target_format=ExportPDFTargetFormat.DOCX)\n",
    "            export_pdf_job = ExportPDFJob(input_asset=input_asset, export_pdf_params=export_pdf_params)\n",
    "\n",
    "            location = self.pdf_services.submit(export_pdf_job)\n",
    "            pdf_services_response = self.pdf_services.get_job_result(location, ExportPDFResult)\n",
    "\n",
    "            result_asset: CloudAsset = pdf_services_response.get_result().get_asset()\n",
    "            stream_asset: StreamAsset = self.pdf_services.get_content(result_asset)\n",
    "\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".docx\", delete=False) as temp_file:\n",
    "                temp_file_path = temp_file.name\n",
    "                with open(temp_file_path, \"wb\") as file:\n",
    "                    file.write(stream_asset.get_input_stream())\n",
    "\n",
    "            return temp_file_path\n",
    "\n",
    "        except ServiceApiException as e:\n",
    "            if \"CORRUPT_DOCUMENT\" in str(e):\n",
    "                logging.error(f\"The input PDF file appears to be corrupted: {e}\")\n",
    "                return \"CORRUPT_DOCUMENT\"\n",
    "            else:\n",
    "                logging.exception(f'Service API Exception encountered while converting PDF: {e}')\n",
    "                return None\n",
    "        except (ServiceUsageException, SdkException) as e:\n",
    "            logging.exception(f'Exception encountered while converting PDF: {e}')\n",
    "            return None\n",
    "\n",
    "def clean_text_with_bert(text):\n",
    "    # Load pre-trained BERT model and tokenizer\n",
    "    model_name = \"bert-base-uncased\"  # You can change this to a different BERT model\n",
    "    model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "    # Prepare the input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    # Get model output\n",
    "    outputs = model(**inputs)\n",
    "    predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "    # Based on the predicted label, perform appropriate cleaning\n",
    "    if predicted_label == 0:  # Assuming label 0 corresponds to \"clean\" text\n",
    "        cleaned_text = text\n",
    "    else:\n",
    "        # Perform cleaning based on the predicted label\n",
    "        cleaned_text = perform_cleaning(text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def perform_cleaning(text):\n",
    "    # Example cleaning logic: remove stop words and punctuation\n",
    "    stop_words = set([\"the\", \"and\", \"in\", \"of\", \"to\", \"for\", \"with\", \"that\", \"it\", \"is\", \"as\", \"this\", \"be\", \"have\", \"not\", \"but\", \"by\", \"from\", \"at\", \"on\", \"or\", \"are\"])\n",
    "    cleaned_text = \" \".join([word for word in text.split() if word not in stop_words and word.isalnum()])\n",
    "    return cleaned_text\n",
    "\n",
    "def process_pdf(pdf_file):\n",
    "    try:\n",
    "        # Create a temporary file to store the uploaded PDF\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_pdf:\n",
    "            temp_pdf_path = temp_pdf.name\n",
    "            # Write the content of the uploaded file to the temporary file\n",
    "            if isinstance(pdf_file, str):\n",
    "                # If pdf_file is a string (file path), write its contents\n",
    "                with open(pdf_file, 'rb') as f:\n",
    "                    temp_pdf.write(f.read())\n",
    "            else:\n",
    "                # If pdf_file is bytes or a file-like object, write it directly\n",
    "                temp_pdf.write(pdf_file)\n",
    "        \n",
    "        # Convert PDF to DOCX\n",
    "        exporter = ExportPDFToDOCX(temp_pdf_path)\n",
    "        docx_file = exporter.process()\n",
    "\n",
    "        if docx_file is None:\n",
    "            return \"An error occurred during PDF to DOCX conversion.\"\n",
    "        elif docx_file == \"CORRUPT_DOCUMENT\":\n",
    "            return \"The uploaded PDF file appears to be corrupted. Please check the file and try again.\"\n",
    "\n",
    "        # Read DOCX content\n",
    "        import docx2txt\n",
    "        text = docx2txt.process(docx_file)\n",
    "\n",
    "        # Clean text using BERT\n",
    "        cleaned_text = clean_text_with_bert(text)\n",
    "\n",
    "        # Clean up temporary files\n",
    "        os.remove(temp_pdf_path)\n",
    "        os.remove(docx_file)\n",
    "\n",
    "        return cleaned_text\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"Error processing PDF: {e}\")\n",
    "        return f\"An error occurred while processing the PDF: {str(e)}\"\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_pdf,\n",
    "    inputs=gr.File(label=\"Upload PDF\", type=\"binary\"),\n",
    "    outputs=gr.Textbox(label=\"Cleaned Document\"),\n",
    "    title=\"PDF Cleaner\",\n",
    "    description=\"Upload a PDF file to convert it to DOCX and clean the text using BERT.\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7872/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7872/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started submitting EXPORT_PDF job\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished polling for status\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting content\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting content\n",
      "C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#### testing version\n",
    "import gradio as gr\n",
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.style import WD_STYLE_TYPE\n",
    "\n",
    "from adobe.pdfservices.operation.auth.service_principal_credentials import ServicePrincipalCredentials\n",
    "from adobe.pdfservices.operation.exception.exceptions import ServiceApiException, ServiceUsageException, SdkException\n",
    "from adobe.pdfservices.operation.io.cloud_asset import CloudAsset\n",
    "from adobe.pdfservices.operation.io.stream_asset import StreamAsset\n",
    "from adobe.pdfservices.operation.pdf_services import PDFServices\n",
    "from adobe.pdfservices.operation.pdf_services_media_type import PDFServicesMediaType\n",
    "from adobe.pdfservices.operation.pdfjobs.jobs.export_pdf_job import ExportPDFJob\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_params import ExportPDFParams\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_target_format import ExportPDFTargetFormat\n",
    "from adobe.pdfservices.operation.pdfjobs.result.export_pdf_result import ExportPDFResult\n",
    "\n",
    "# Initialize the logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class ExportPDFToDOCX:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.credentials = ServicePrincipalCredentials(\n",
    "            client_id=os.getenv('PDF_SERVICES_CLIENT_ID'),\n",
    "            client_secret=os.getenv('PDF_SERVICES_CLIENT_SECRET')\n",
    "        )\n",
    "        self.pdf_services = PDFServices(credentials=self.credentials)\n",
    "\n",
    "    def process(self):\n",
    "        try:\n",
    "            with open(self.pdf_path, 'rb') as file:\n",
    "                input_stream = file.read()\n",
    "\n",
    "            input_asset = self.pdf_services.upload(input_stream=input_stream, mime_type=PDFServicesMediaType.PDF)\n",
    "            export_pdf_params = ExportPDFParams(target_format=ExportPDFTargetFormat.DOCX)\n",
    "            export_pdf_job = ExportPDFJob(input_asset=input_asset, export_pdf_params=export_pdf_params)\n",
    "\n",
    "            location = self.pdf_services.submit(export_pdf_job)\n",
    "            pdf_services_response = self.pdf_services.get_job_result(location, ExportPDFResult)\n",
    "\n",
    "            result_asset: CloudAsset = pdf_services_response.get_result().get_asset()\n",
    "            stream_asset: StreamAsset = self.pdf_services.get_content(result_asset)\n",
    "\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".docx\", delete=False) as temp_file:\n",
    "                temp_file_path = temp_file.name\n",
    "                with open(temp_file_path, \"wb\") as file:\n",
    "                    file.write(stream_asset.get_input_stream())\n",
    "\n",
    "            return temp_file_path\n",
    "\n",
    "        except ServiceApiException as e:\n",
    "            if \"CORRUPT_DOCUMENT\" in str(e):\n",
    "                logging.error(f\"The input PDF file appears to be corrupted: {e}\")\n",
    "                return \"CORRUPT_DOCUMENT\"\n",
    "            else:\n",
    "                logging.exception(f'Service API Exception encountered while converting PDF: {e}')\n",
    "                return None\n",
    "        except (ServiceUsageException, SdkException) as e:\n",
    "            logging.exception(f'Exception encountered while converting PDF: {e}')\n",
    "            return None\n",
    "\n",
    "def clean_text_with_bert(text):\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "    # Split text into smaller chunks to fit BERT's max token limit\n",
    "    max_length = tokenizer.model_max_length\n",
    "    chunks = [text[i:i+max_length] for i in range(0, len(text), max_length)]\n",
    "\n",
    "    cleaned_chunks = []\n",
    "    for chunk in chunks:\n",
    "        inputs = tokenizer(chunk, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        outputs = model(**inputs)\n",
    "        predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "        if predicted_label == 0:  # Assuming label 0 corresponds to \"clean\" text\n",
    "            cleaned_chunks.append(chunk)\n",
    "        else:\n",
    "            cleaned_chunks.append(perform_cleaning(chunk))\n",
    "\n",
    "    return \" \".join(cleaned_chunks)\n",
    "\n",
    "def perform_cleaning(text):\n",
    "    # Basic cleaning: remove extra whitespace and normalize punctuation\n",
    "    cleaned_text = \" \".join(text.split())\n",
    "    cleaned_text = cleaned_text.replace(\" ,\", \",\").replace(\" .\", \".\").replace(\" :\", \":\")\n",
    "    return cleaned_text\n",
    "\n",
    "def detect_formatting(text):\n",
    "    lines = text.split('\\n')\n",
    "    formatted_lines = []\n",
    "    for line in lines:\n",
    "        if line.isupper():\n",
    "            formatted_lines.append(('heading', line))\n",
    "        elif line.strip().startswith(('', '-', '*')):\n",
    "            formatted_lines.append(('bullet', line))\n",
    "        elif len(line.strip()) > 0:\n",
    "            formatted_lines.append(('paragraph', line))\n",
    "    return formatted_lines\n",
    "\n",
    "def create_formatted_docx(text, output_path):\n",
    "    doc = Document()\n",
    "    \n",
    "    # Define styles\n",
    "    styles = doc.styles\n",
    "    heading_style = styles.add_style('CustomHeading', WD_STYLE_TYPE.PARAGRAPH)\n",
    "    heading_style.font.size = Pt(14)\n",
    "    heading_style.font.bold = True\n",
    "    \n",
    "    paragraph_style = styles.add_style('CustomParagraph', WD_STYLE_TYPE.PARAGRAPH)\n",
    "    paragraph_style.font.size = Pt(11)\n",
    "    \n",
    "    bullet_style = styles.add_style('CustomBullet', WD_STYLE_TYPE.PARAGRAPH)\n",
    "    bullet_style.font.size = Pt(11)\n",
    "    \n",
    "    formatted_lines = detect_formatting(text)\n",
    "    \n",
    "    for format_type, content in formatted_lines:\n",
    "        if format_type == 'heading':\n",
    "            doc.add_paragraph(content, style='CustomHeading')\n",
    "        elif format_type == 'bullet':\n",
    "            doc.add_paragraph(content, style='CustomBullet')\n",
    "        else:\n",
    "            doc.add_paragraph(content, style='CustomParagraph')\n",
    "    \n",
    "    doc.save(output_path)\n",
    "\n",
    "def process_pdf(pdf_file):\n",
    "    try:\n",
    "        # Create a temporary file to store the uploaded PDF\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_pdf:\n",
    "            temp_pdf_path = temp_pdf.name\n",
    "            temp_pdf.write(pdf_file if isinstance(pdf_file, bytes) else pdf_file.read())\n",
    "        \n",
    "        # Convert PDF to DOCX\n",
    "        exporter = ExportPDFToDOCX(temp_pdf_path)\n",
    "        docx_file = exporter.process()\n",
    "\n",
    "        if docx_file is None:\n",
    "            return \"Error occurred during PDF to DOCX conversion.\"\n",
    "        elif docx_file == \"CORRUPT_DOCUMENT\":\n",
    "            return \"The uploaded PDF file appears to be corrupted. Please check the file and try again.\"\n",
    "\n",
    "        # Read DOCX content\n",
    "        import docx2txt\n",
    "        text = docx2txt.process(docx_file)\n",
    "\n",
    "        # Clean text using BERT\n",
    "        cleaned_text = clean_text_with_bert(text)\n",
    "\n",
    "        # Create formatted DOCX\n",
    "        output_docx_path = temp_pdf_path.replace('.pdf', '_formatted.docx')\n",
    "        create_formatted_docx(cleaned_text, output_docx_path)\n",
    "\n",
    "        # Clean up temporary files\n",
    "        os.remove(temp_pdf_path)\n",
    "        os.remove(docx_file)\n",
    "\n",
    "        return output_docx_path\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"Error processing PDF: {e}\")\n",
    "        return f\"An error occurred while processing the PDF: {str(e)}\"\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_pdf,\n",
    "    inputs=gr.File(label=\"Upload PDF\", type=\"binary\"),\n",
    "    outputs=gr.File(label=\"Download Formatted DOCX\"),\n",
    "    title=\"PDF Cleaner and Formatter\",\n",
    "    description=\"Upload a PDF file to convert it to a formatted DOCX document.\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7873/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7873/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7873\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7873/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started submitting EXPORT_PDF job\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished polling for status\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting content\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting content\n",
      "C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "ERROR:root:Error processing PDF: random_ expects 'from' to be less than 'to', but got from=0 >= to=0\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\austi\\AppData\\Local\\Temp\\ipykernel_26020\\2588016612.py\", line 174, in process_pdf\n",
      "    improved_text = improve_text_with_bert(text)\n",
      "  File \"C:\\Users\\austi\\AppData\\Local\\Temp\\ipykernel_26020\\2588016612.py\", line 88, in improve_text_with_bert\n",
      "    masked_indices = torch.randint(0, len(tokens), (max(1, int(0.15 * len(tokens))),))\n",
      "RuntimeError: random_ expects 'from' to be less than 'to', but got from=0 >= to=0\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\queueing.py\", line 622, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\blocks.py\", line 2026, in process_api\n",
      "    data = await self.postprocess_data(block_fn, result[\"prediction\"], state)\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\blocks.py\", line 1832, in postprocess_data\n",
      "    prediction_value = block.postprocess(prediction_value)\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\gradio\\components\\file.py\", line 213, in postprocess\n",
      "    size=Path(value).stat().st_size,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\pathlib.py\", line 1097, in stat\n",
      "    return self._accessor.stat(self, follow_symlinks=follow_symlinks)\n",
      "FileNotFoundError: [WinError 2] The system cannot find the file specified: \"An error occurred while processing the PDF: random_ expects 'from' to be less than 'to', but got from=0 >= to=0\"\n"
     ]
    }
   ],
   "source": [
    "### multiple bert pass throughs\n",
    "\n",
    "import gradio as gr\n",
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, BertForMaskedLM, pipeline\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.style import WD_STYLE_TYPE\n",
    "import language_tool_python\n",
    "\n",
    "from adobe.pdfservices.operation.auth.service_principal_credentials import ServicePrincipalCredentials\n",
    "from adobe.pdfservices.operation.exception.exceptions import ServiceApiException, ServiceUsageException, SdkException\n",
    "from adobe.pdfservices.operation.io.cloud_asset import CloudAsset\n",
    "from adobe.pdfservices.operation.io.stream_asset import StreamAsset\n",
    "from adobe.pdfservices.operation.pdf_services import PDFServices\n",
    "from adobe.pdfservices.operation.pdf_services_media_type import PDFServicesMediaType\n",
    "from adobe.pdfservices.operation.pdfjobs.jobs.export_pdf_job import ExportPDFJob\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_params import ExportPDFParams\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_target_format import ExportPDFTargetFormat\n",
    "from adobe.pdfservices.operation.pdfjobs.result.export_pdf_result import ExportPDFResult\n",
    "\n",
    "# Initialize the logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class ExportPDFToDOCX:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.credentials = ServicePrincipalCredentials(\n",
    "            client_id=os.getenv('PDF_SERVICES_CLIENT_ID'),\n",
    "            client_secret=os.getenv('PDF_SERVICES_CLIENT_SECRET')\n",
    "        )\n",
    "        self.pdf_services = PDFServices(credentials=self.credentials)\n",
    "\n",
    "    def process(self):\n",
    "        try:\n",
    "            with open(self.pdf_path, 'rb') as file:\n",
    "                input_stream = file.read()\n",
    "\n",
    "            input_asset = self.pdf_services.upload(input_stream=input_stream, mime_type=PDFServicesMediaType.PDF)\n",
    "            export_pdf_params = ExportPDFParams(target_format=ExportPDFTargetFormat.DOCX)\n",
    "            export_pdf_job = ExportPDFJob(input_asset=input_asset, export_pdf_params=export_pdf_params)\n",
    "\n",
    "            location = self.pdf_services.submit(export_pdf_job)\n",
    "            pdf_services_response = self.pdf_services.get_job_result(location, ExportPDFResult)\n",
    "\n",
    "            result_asset: CloudAsset = pdf_services_response.get_result().get_asset()\n",
    "            stream_asset: StreamAsset = self.pdf_services.get_content(result_asset)\n",
    "\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".docx\", delete=False) as temp_file:\n",
    "                temp_file_path = temp_file.name\n",
    "                with open(temp_file_path, \"wb\") as file:\n",
    "                    file.write(stream_asset.get_input_stream())\n",
    "\n",
    "            return temp_file_path\n",
    "\n",
    "        except ServiceApiException as e:\n",
    "            if \"CORRUPT_DOCUMENT\" in str(e):\n",
    "                logging.error(f\"The input PDF file appears to be corrupted: {e}\")\n",
    "                return \"CORRUPT_DOCUMENT\"\n",
    "            else:\n",
    "                logging.exception(f'Service API Exception encountered while converting PDF: {e}')\n",
    "                return None\n",
    "        except (ServiceUsageException, SdkException) as e:\n",
    "            logging.exception(f'Exception encountered while converting PDF: {e}')\n",
    "            return None\n",
    "\n",
    "def improve_text_with_bert(text):\n",
    "    # Load pre-trained BERT model for masked language modeling\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    model = BertForMaskedLM.from_pretrained(model_name)\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "    # Create a fill-mask pipeline\n",
    "    fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "    # Split text into sentences\n",
    "    sentences = text.split('.')\n",
    "    improved_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Tokenize the sentence\n",
    "        tokens = tokenizer.tokenize(sentence)\n",
    "        \n",
    "        # Randomly mask some tokens (e.g., 15% of tokens)\n",
    "        masked_indices = torch.randint(0, len(tokens), (max(1, int(0.15 * len(tokens))),))\n",
    "        for idx in masked_indices:\n",
    "            tokens[idx] = \"[MASK]\"\n",
    "        \n",
    "        # Convert back to a string\n",
    "        masked_sentence = tokenizer.convert_tokens_to_string(tokens)\n",
    "        \n",
    "        # Use the fill-mask pipeline to predict masked tokens\n",
    "        results = fill_mask(masked_sentence)\n",
    "        \n",
    "        # Replace masked tokens with the most likely predictions\n",
    "        for result in results:\n",
    "            masked_sentence = masked_sentence.replace(\"[MASK]\", result['token_str'], 1)\n",
    "        \n",
    "        improved_sentences.append(masked_sentence)\n",
    "\n",
    "    # Join improved sentences\n",
    "    improved_text = '. '.join(improved_sentences)\n",
    "\n",
    "    return improved_text\n",
    "\n",
    "def fix_spelling_and_grammar(text):\n",
    "    tool = language_tool_python.LanguageTool('en-US')\n",
    "    corrected_text = tool.correct(text)\n",
    "    return corrected_text\n",
    "\n",
    "def detect_formatting(text):\n",
    "    lines = text.split('\\n')\n",
    "    formatted_lines = []\n",
    "    for line in lines:\n",
    "        if line.isupper():\n",
    "            formatted_lines.append(('heading', line))\n",
    "        elif line.strip().startswith(('', '-', '*')):\n",
    "            formatted_lines.append(('bullet', line))\n",
    "        elif len(line.strip()) > 0:\n",
    "            formatted_lines.append(('paragraph', line))\n",
    "    return formatted_lines\n",
    "\n",
    "def create_formatted_docx(text, output_path):\n",
    "    doc = Document()\n",
    "    \n",
    "    # Define styles\n",
    "    styles = doc.styles\n",
    "    heading_style = styles.add_style('CustomHeading', WD_STYLE_TYPE.PARAGRAPH)\n",
    "    heading_style.font.size = Pt(14)\n",
    "    heading_style.font.bold = True\n",
    "    \n",
    "    paragraph_style = styles.add_style('CustomParagraph', WD_STYLE_TYPE.PARAGRAPH)\n",
    "    paragraph_style.font.size = Pt(11)\n",
    "    \n",
    "    bullet_style = styles.add_style('CustomBullet', WD_STYLE_TYPE.PARAGRAPH)\n",
    "    bullet_style.font.size = Pt(11)\n",
    "    \n",
    "    formatted_lines = detect_formatting(text)\n",
    "    \n",
    "    for format_type, content in formatted_lines:\n",
    "        if format_type == 'heading':\n",
    "            doc.add_paragraph(content, style='CustomHeading')\n",
    "        elif format_type == 'bullet':\n",
    "            doc.add_paragraph(content, style='CustomBullet')\n",
    "        else:\n",
    "            doc.add_paragraph(content, style='CustomParagraph')\n",
    "    \n",
    "    doc.save(output_path)\n",
    "\n",
    "def process_pdf(pdf_file):\n",
    "    try:\n",
    "        # Create a temporary file to store the uploaded PDF\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_pdf:\n",
    "            temp_pdf_path = temp_pdf.name\n",
    "            temp_pdf.write(pdf_file if isinstance(pdf_file, bytes) else pdf_file.read())\n",
    "        \n",
    "        # Convert PDF to DOCX\n",
    "        exporter = ExportPDFToDOCX(temp_pdf_path)\n",
    "        docx_file = exporter.process()\n",
    "\n",
    "        if docx_file is None:\n",
    "            return \"Error occurred during PDF to DOCX conversion.\"\n",
    "        elif docx_file == \"CORRUPT_DOCUMENT\":\n",
    "            return \"The uploaded PDF file appears to be corrupted. Please check the file and try again.\"\n",
    "\n",
    "        # Read DOCX content\n",
    "        import docx2txt\n",
    "        text = docx2txt.process(docx_file)\n",
    "\n",
    "        # Improve text using BERT\n",
    "        improved_text = improve_text_with_bert(text)\n",
    "\n",
    "        # Fix spelling and grammar\n",
    "        corrected_text = fix_spelling_and_grammar(improved_text)\n",
    "\n",
    "        # Create formatted DOCX\n",
    "        output_docx_path = temp_pdf_path.replace('.pdf', '_formatted.docx')\n",
    "        create_formatted_docx(corrected_text, output_docx_path)\n",
    "\n",
    "        # Clean up temporary files\n",
    "        os.remove(temp_pdf_path)\n",
    "        os.remove(docx_file)\n",
    "\n",
    "        return output_docx_path\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"Error processing PDF: {e}\")\n",
    "        return f\"An error occurred while processing the PDF: {str(e)}\"\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_pdf,\n",
    "    inputs=gr.File(label=\"Upload PDF\", type=\"binary\"),\n",
    "    outputs=gr.File(label=\"Download Formatted DOCX\"),\n",
    "    title=\"PDF Cleaner, Improver, and Formatter\",\n",
    "    description=\"Upload a PDF file to convert it to a formatted DOCX document with improved readability and corrected spelling/grammar.\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7875/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7875/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7875\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7875/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started submitting EXPORT_PDF job\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished polling for status\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting content\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting content\n",
      "C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading LanguageTool 6.4: 100%|| 246M/246M [00:03<00:00, 68.3MB/s] \n",
      "INFO:language_tool_python.download_lt:Unzipping C:\\Users\\austi\\AppData\\Local\\Temp\\tmp3a65b3go.zip to C:\\Users\\austi\\.cache\\language_tool_python.\n",
      "INFO:language_tool_python.download_lt:Downloaded https://www.languagetool.org/download/LanguageTool-6.4.zip to C:\\Users\\austi\\.cache\\language_tool_python.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForMaskedLM, pipeline\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.style import WD_STYLE_TYPE\n",
    "import language_tool_python\n",
    "\n",
    "from adobe.pdfservices.operation.auth.service_principal_credentials import ServicePrincipalCredentials\n",
    "from adobe.pdfservices.operation.exception.exceptions import ServiceApiException, ServiceUsageException, SdkException\n",
    "from adobe.pdfservices.operation.io.cloud_asset import CloudAsset\n",
    "from adobe.pdfservices.operation.io.stream_asset import StreamAsset\n",
    "from adobe.pdfservices.operation.pdf_services import PDFServices\n",
    "from adobe.pdfservices.operation.pdf_services_media_type import PDFServicesMediaType\n",
    "from adobe.pdfservices.operation.pdfjobs.jobs.export_pdf_job import ExportPDFJob\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_params import ExportPDFParams\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_target_format import ExportPDFTargetFormat\n",
    "from adobe.pdfservices.operation.pdfjobs.result.export_pdf_result import ExportPDFResult\n",
    "\n",
    "# Initialize the logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class ExportPDFToDOCX:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.credentials = ServicePrincipalCredentials(\n",
    "            client_id=os.getenv('PDF_SERVICES_CLIENT_ID'),\n",
    "            client_secret=os.getenv('PDF_SERVICES_CLIENT_SECRET')\n",
    "        )\n",
    "        self.pdf_services = PDFServices(credentials=self.credentials)\n",
    "\n",
    "    def process(self):\n",
    "        try:\n",
    "            with open(self.pdf_path, 'rb') as file:\n",
    "                input_stream = file.read()\n",
    "\n",
    "            input_asset = self.pdf_services.upload(input_stream=input_stream, mime_type=PDFServicesMediaType.PDF)\n",
    "            export_pdf_params = ExportPDFParams(target_format=ExportPDFTargetFormat.DOCX)\n",
    "            export_pdf_job = ExportPDFJob(input_asset=input_asset, export_pdf_params=export_pdf_params)\n",
    "\n",
    "            location = self.pdf_services.submit(export_pdf_job)\n",
    "            pdf_services_response = self.pdf_services.get_job_result(location, ExportPDFResult)\n",
    "\n",
    "            result_asset: CloudAsset = pdf_services_response.get_result().get_asset()\n",
    "            stream_asset: StreamAsset = self.pdf_services.get_content(result_asset)\n",
    "\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".docx\", delete=False) as temp_file:\n",
    "                temp_file_path = temp_file.name\n",
    "                with open(temp_file_path, \"wb\") as file:\n",
    "                    file.write(stream_asset.get_input_stream())\n",
    "\n",
    "            return temp_file_path\n",
    "\n",
    "        except ServiceApiException as e:\n",
    "            if \"CORRUPT_DOCUMENT\" in str(e):\n",
    "                logging.error(f\"The input PDF file appears to be corrupted: {e}\")\n",
    "                return \"CORRUPT_DOCUMENT\"\n",
    "            else:\n",
    "                logging.exception(f'Service API Exception encountered while converting PDF: {e}')\n",
    "                return None\n",
    "        except (ServiceUsageException, SdkException) as e:\n",
    "            logging.exception(f'Exception encountered while converting PDF: {e}')\n",
    "            return None\n",
    "\n",
    "def improve_text_with_bert(text):\n",
    "    if not text.strip():\n",
    "        return \"The extracted text is empty. Please check the input PDF file.\"\n",
    "\n",
    "    # Load pre-trained BERT model for masked language modeling\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    model = BertForMaskedLM.from_pretrained(model_name)\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "    # Create a fill-mask pipeline\n",
    "    fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "    # Split text into sentences\n",
    "    sentences = text.split('.')\n",
    "    improved_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Tokenize the sentence\n",
    "        tokens = tokenizer.tokenize(sentence)\n",
    "        \n",
    "        if not tokens:\n",
    "            continue\n",
    "        \n",
    "        # Randomly mask some tokens (e.g., 15% of tokens)\n",
    "        num_masks = max(1, int(0.15 * len(tokens)))\n",
    "        masked_indices = torch.randint(0, len(tokens), (num_masks,))\n",
    "        for idx in masked_indices:\n",
    "            tokens[idx] = \"[MASK]\"\n",
    "        \n",
    "        # Convert back to a string\n",
    "        masked_sentence = tokenizer.convert_tokens_to_string(tokens)\n",
    "        \n",
    "        # Use the fill-mask pipeline to predict masked tokens\n",
    "        results = fill_mask(masked_sentence)\n",
    "        \n",
    "        # Replace masked tokens with the most likely predictions\n",
    "        for result in results:\n",
    "            if isinstance(result, dict) and 'token_str' in result:\n",
    "                masked_sentence = masked_sentence.replace(\"[MASK]\", result['token_str'], 1)\n",
    "            elif isinstance(result, list) and len(result) > 0 and 'token_str' in result[0]:\n",
    "                masked_sentence = masked_sentence.replace(\"[MASK]\", result[0]['token_str'], 1)\n",
    "        \n",
    "        improved_sentences.append(masked_sentence)\n",
    "\n",
    "    # Join improved sentences\n",
    "    improved_text = '. '.join(improved_sentences)\n",
    "\n",
    "    return improved_text\n",
    "\n",
    "def fix_spelling_and_grammar(text):\n",
    "    if not text.strip():\n",
    "        return \"The input text is empty. Unable to perform spelling and grammar check.\"\n",
    "\n",
    "    tool = language_tool_python.LanguageTool('en-US')\n",
    "    corrected_text = tool.correct(text)\n",
    "    return corrected_text\n",
    "\n",
    "def detect_formatting(text):\n",
    "    lines = text.split('\\n')\n",
    "    formatted_lines = []\n",
    "    for line in lines:\n",
    "        if line.isupper():\n",
    "            formatted_lines.append(('heading', line))\n",
    "        elif line.strip().startswith(('', '-', '*')):\n",
    "            formatted_lines.append(('bullet', line))\n",
    "        elif len(line.strip()) > 0:\n",
    "            formatted_lines.append(('paragraph', line))\n",
    "    return formatted_lines\n",
    "\n",
    "def create_formatted_docx(text, output_path):\n",
    "    doc = Document()\n",
    "    \n",
    "    # Define styles\n",
    "    styles = doc.styles\n",
    "    heading_style = styles.add_style('CustomHeading', WD_STYLE_TYPE.PARAGRAPH)\n",
    "    heading_style.font.size = Pt(14)\n",
    "    heading_style.font.bold = True\n",
    "    \n",
    "    paragraph_style = styles.add_style('CustomParagraph', WD_STYLE_TYPE.PARAGRAPH)\n",
    "    paragraph_style.font.size = Pt(11)\n",
    "    \n",
    "    bullet_style = styles.add_style('CustomBullet', WD_STYLE_TYPE.PARAGRAPH)\n",
    "    bullet_style.font.size = Pt(11)\n",
    "    \n",
    "    formatted_lines = detect_formatting(text)\n",
    "    \n",
    "    for format_type, content in formatted_lines:\n",
    "        if format_type == 'heading':\n",
    "            doc.add_paragraph(content, style='CustomHeading')\n",
    "        elif format_type == 'bullet':\n",
    "            doc.add_paragraph(content, style='CustomBullet')\n",
    "        else:\n",
    "            doc.add_paragraph(content, style='CustomParagraph')\n",
    "    \n",
    "    doc.save(output_path)\n",
    "\n",
    "def process_pdf(pdf_file):\n",
    "    try:\n",
    "        # Create a temporary file to store the uploaded PDF\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_pdf:\n",
    "            temp_pdf_path = temp_pdf.name\n",
    "            temp_pdf.write(pdf_file if isinstance(pdf_file, bytes) else pdf_file.read())\n",
    "        \n",
    "        # Convert PDF to DOCX\n",
    "        exporter = ExportPDFToDOCX(temp_pdf_path)\n",
    "        docx_file = exporter.process()\n",
    "\n",
    "        if docx_file is None:\n",
    "            return \"Error occurred during PDF to DOCX conversion.\"\n",
    "        elif docx_file == \"CORRUPT_DOCUMENT\":\n",
    "            return \"The uploaded PDF file appears to be corrupted. Please check the file and try again.\"\n",
    "\n",
    "        # Read DOCX content\n",
    "        import docx2txt\n",
    "        text = docx2txt.process(docx_file)\n",
    "\n",
    "        if not text.strip():\n",
    "            return \"The extracted text is empty. Please check the input PDF file.\"\n",
    "\n",
    "        try:\n",
    "            # Improve text using BERT\n",
    "            improved_text = improve_text_with_bert(text)\n",
    "        except Exception as e:\n",
    "            logging.exception(f\"Error in BERT processing: {e}\")\n",
    "            improved_text = text  # Fall back to original text if BERT processing fails\n",
    "\n",
    "        # Fix spelling and grammar\n",
    "        corrected_text = fix_spelling_and_grammar(improved_text)\n",
    "\n",
    "        # Create formatted DOCX\n",
    "        output_docx_path = temp_pdf_path.replace('.pdf', '_formatted.docx')\n",
    "        create_formatted_docx(corrected_text, output_docx_path)\n",
    "\n",
    "        # Clean up temporary files\n",
    "        os.remove(temp_pdf_path)\n",
    "        os.remove(docx_file)\n",
    "\n",
    "        return output_docx_path\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"Error processing PDF: {e}\")\n",
    "        return f\"An error occurred while processing the PDF: {str(e)}\"\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_pdf,\n",
    "    inputs=gr.File(label=\"Upload PDF\", type=\"binary\"),\n",
    "    outputs=gr.File(label=\"Download Formatted DOCX\"),\n",
    "    title=\"PDF Cleaner, Improver, and Formatter\",\n",
    "    description=\"Upload a PDF file to convert it to a formatted DOCX document with improved readability and corrected spelling/grammar.\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7877/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7877/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7877\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7877/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started submitting EXPORT_PDF job\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished polling for status\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting content\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting content\n",
      "C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#### revised app\n",
    "import gradio as gr\n",
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForMaskedLM, pipeline\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.style import WD_STYLE_TYPE\n",
    "import language_tool_python\n",
    "import re\n",
    "\n",
    "from adobe.pdfservices.operation.auth.service_principal_credentials import ServicePrincipalCredentials\n",
    "from adobe.pdfservices.operation.exception.exceptions import ServiceApiException, ServiceUsageException, SdkException\n",
    "from adobe.pdfservices.operation.io.cloud_asset import CloudAsset\n",
    "from adobe.pdfservices.operation.io.stream_asset import StreamAsset\n",
    "from adobe.pdfservices.operation.pdf_services import PDFServices\n",
    "from adobe.pdfservices.operation.pdf_services_media_type import PDFServicesMediaType\n",
    "from adobe.pdfservices.operation.pdfjobs.jobs.export_pdf_job import ExportPDFJob\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_params import ExportPDFParams\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_target_format import ExportPDFTargetFormat\n",
    "from adobe.pdfservices.operation.pdfjobs.result.export_pdf_result import ExportPDFResult\n",
    "\n",
    "# Initialize the logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class ExportPDFToDOCX:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.credentials = ServicePrincipalCredentials(\n",
    "            client_id=os.getenv('PDF_SERVICES_CLIENT_ID'),\n",
    "            client_secret=os.getenv('PDF_SERVICES_CLIENT_SECRET')\n",
    "        )\n",
    "        self.pdf_services = PDFServices(credentials=self.credentials)\n",
    "\n",
    "    def process(self):\n",
    "        try:\n",
    "            with open(self.pdf_path, 'rb') as file:\n",
    "                input_stream = file.read()\n",
    "\n",
    "            input_asset = self.pdf_services.upload(input_stream=input_stream, mime_type=PDFServicesMediaType.PDF)\n",
    "            export_pdf_params = ExportPDFParams(target_format=ExportPDFTargetFormat.DOCX)\n",
    "            export_pdf_job = ExportPDFJob(input_asset=input_asset, export_pdf_params=export_pdf_params)\n",
    "\n",
    "            location = self.pdf_services.submit(export_pdf_job)\n",
    "            pdf_services_response = self.pdf_services.get_job_result(location, ExportPDFResult)\n",
    "\n",
    "            result_asset: CloudAsset = pdf_services_response.get_result().get_asset()\n",
    "            stream_asset: StreamAsset = self.pdf_services.get_content(result_asset)\n",
    "\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".docx\", delete=False) as temp_file:\n",
    "                temp_file_path = temp_file.name\n",
    "                with open(temp_file_path, \"wb\") as file:\n",
    "                    file.write(stream_asset.get_input_stream())\n",
    "\n",
    "            return temp_file_path\n",
    "\n",
    "        except ServiceApiException as e:\n",
    "            if \"CORRUPT_DOCUMENT\" in str(e):\n",
    "                logging.error(f\"The input PDF file appears to be corrupted: {e}\")\n",
    "                return \"CORRUPT_DOCUMENT\"\n",
    "            else:\n",
    "                logging.exception(f'Service API Exception encountered while converting PDF: {e}')\n",
    "                return None\n",
    "        except (ServiceUsageException, SdkException) as e:\n",
    "            logging.exception(f'Exception encountered while converting PDF: {e}')\n",
    "            return None\n",
    "\n",
    "def improve_text_with_bert(text):\n",
    "    if not text.strip():\n",
    "        return \"The extracted text is empty. Please check the input PDF file.\"\n",
    "\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    model = BertForMaskedLM.from_pretrained(model_name)\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "    fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "    sentences = text.split('.')\n",
    "    improved_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer.tokenize(sentence)\n",
    "        \n",
    "        if not tokens:\n",
    "            continue\n",
    "        \n",
    "        num_masks = max(1, int(0.15 * len(tokens)))\n",
    "        masked_indices = torch.randint(0, len(tokens), (num_masks,))\n",
    "        for idx in masked_indices:\n",
    "            tokens[idx] = \"[MASK]\"\n",
    "        \n",
    "        masked_sentence = tokenizer.convert_tokens_to_string(tokens)\n",
    "        \n",
    "        results = fill_mask(masked_sentence)\n",
    "        \n",
    "        for result in results:\n",
    "            if isinstance(result, dict) and 'token_str' in result:\n",
    "                masked_sentence = masked_sentence.replace(\"[MASK]\", result['token_str'], 1)\n",
    "            elif isinstance(result, list) and len(result) > 0 and 'token_str' in result[0]:\n",
    "                masked_sentence = masked_sentence.replace(\"[MASK]\", result[0]['token_str'], 1)\n",
    "        \n",
    "        improved_sentences.append(masked_sentence)\n",
    "\n",
    "    improved_text = '. '.join(improved_sentences)\n",
    "\n",
    "    return improved_text\n",
    "\n",
    "def fix_spelling_and_grammar(text):\n",
    "    if not text.strip():\n",
    "        return \"The input text is empty. Unable to perform spelling and grammar check.\"\n",
    "\n",
    "    tool = language_tool_python.LanguageTool('en-US')\n",
    "    corrected_text = tool.correct(text)\n",
    "    return corrected_text\n",
    "\n",
    "def format_document(text):\n",
    "    # Remove page header information\n",
    "    text = re.sub(r'WORCESTER COUNTY CIRCUIT COURT.*\\n', '', text)\n",
    "    \n",
    "    # Format title\n",
    "    title = \"SUPPLEMENTARY DECLARATION, CONDITIONS AND RESTRICTIONS\\nTIME SHARING OWNERSHIP - BAY CLUB CONDOMINIUM\"\n",
    "    if \"TIME SHARING OWNERSHIP - BAY CLUB CONDOMINIUM\" in text:\n",
    "        text = title + \"\\n\\n\" + text.split(\"TIME SHARING OWNERSHIP - BAY CLUB CONDOMINIUM\", 1)[1]\n",
    "    else:\n",
    "        text = title + \"\\n\\n\" + text\n",
    "    \n",
    "    # Format sections\n",
    "    text = re.sub(r'(ARTICLE [IVX]+:? .*)', r'\\n\\n## \\1\\n', text)\n",
    "    text = re.sub(r'([1-9]\\. .*)', r'\\n\\1', text)\n",
    "    \n",
    "    # Clean up extra spaces and newlines\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    text = re.sub(r' {2,}', ' ', text)\n",
    "    \n",
    "    # Add markdown formatting\n",
    "    text = \"# \" + text\n",
    "    \n",
    "    return text\n",
    "\n",
    "def create_formatted_docx(text, output_path):\n",
    "    doc = Document()\n",
    "    \n",
    "    styles = doc.styles\n",
    "    title_style = styles.add_style('CustomTitle', WD_STYLE_TYPE.PARAGRAPH)\n",
    "    title_style.font.size = Pt(16)\n",
    "    title_style.font.bold = True\n",
    "    \n",
    "    heading_style = styles.add_style('CustomHeading', WD_STYLE_TYPE.PARAGRAPH)\n",
    "    heading_style.font.size = Pt(14)\n",
    "    heading_style.font.bold = True\n",
    "    \n",
    "    subheading_style = styles.add_style('CustomSubheading', WD_STYLE_TYPE.PARAGRAPH)\n",
    "    subheading_style.font.size = Pt(12)\n",
    "    subheading_style.font.bold = True\n",
    "    \n",
    "    paragraph_style = styles.add_style('CustomParagraph', WD_STYLE_TYPE.PARAGRAPH)\n",
    "    paragraph_style.font.size = Pt(11)\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    for line in lines:\n",
    "        if line.startswith('# '):\n",
    "            doc.add_paragraph(line[2:], style='CustomTitle')\n",
    "        elif line.startswith('## '):\n",
    "            doc.add_paragraph(line[3:], style='CustomHeading')\n",
    "        elif line.startswith('### '):\n",
    "            doc.add_paragraph(line[4:], style='CustomSubheading')\n",
    "        else:\n",
    "            doc.add_paragraph(line, style='CustomParagraph')\n",
    "    \n",
    "    doc.save(output_path)\n",
    "\n",
    "def process_pdf(pdf_file):\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_pdf:\n",
    "            temp_pdf_path = temp_pdf.name\n",
    "            temp_pdf.write(pdf_file if isinstance(pdf_file, bytes) else pdf_file.read())\n",
    "        \n",
    "        exporter = ExportPDFToDOCX(temp_pdf_path)\n",
    "        docx_file = exporter.process()\n",
    "\n",
    "        if docx_file is None:\n",
    "            return \"Error occurred during PDF to DOCX conversion.\"\n",
    "        elif docx_file == \"CORRUPT_DOCUMENT\":\n",
    "            return \"The uploaded PDF file appears to be corrupted. Please check the file and try again.\"\n",
    "\n",
    "        import docx2txt\n",
    "        text = docx2txt.process(docx_file)\n",
    "\n",
    "        if not text.strip():\n",
    "            return \"The extracted text is empty. Please check the input PDF file.\"\n",
    "\n",
    "        try:\n",
    "            improved_text = improve_text_with_bert(text)\n",
    "        except Exception as e:\n",
    "            logging.exception(f\"Error in BERT processing: {e}\")\n",
    "            improved_text = text\n",
    "\n",
    "        corrected_text = fix_spelling_and_grammar(improved_text)\n",
    "        \n",
    "        formatted_text = format_document(corrected_text)\n",
    "\n",
    "        output_docx_path = temp_pdf_path.replace('.pdf', '_formatted.docx')\n",
    "        create_formatted_docx(formatted_text, output_docx_path)\n",
    "\n",
    "        os.remove(temp_pdf_path)\n",
    "        os.remove(docx_file)\n",
    "\n",
    "        return output_docx_path\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"Error processing PDF: {e}\")\n",
    "        return f\"An error occurred while processing the PDF: {str(e)}\"\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_pdf,\n",
    "    inputs=gr.File(label=\"Upload PDF\", type=\"binary\"),\n",
    "    outputs=gr.File(label=\"Download Formatted DOCX\"),\n",
    "    title=\"PDF Cleaner, Improver, and Formatter\",\n",
    "    description=\"Upload a PDF file to convert it to a formatted DOCX document with improved readability and corrected spelling/grammar.\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7878/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7878/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7878\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7878/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started submitting EXPORT_PDF job\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished polling for status\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting content\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting content\n",
      "C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForMaskedLM, pipeline\n",
    "import language_tool_python\n",
    "import docx2txt\n",
    "\n",
    "from adobe.pdfservices.operation.auth.service_principal_credentials import ServicePrincipalCredentials\n",
    "from adobe.pdfservices.operation.exception.exceptions import ServiceApiException, ServiceUsageException, SdkException\n",
    "from adobe.pdfservices.operation.io.cloud_asset import CloudAsset\n",
    "from adobe.pdfservices.operation.io.stream_asset import StreamAsset\n",
    "from adobe.pdfservices.operation.pdf_services import PDFServices\n",
    "from adobe.pdfservices.operation.pdf_services_media_type import PDFServicesMediaType\n",
    "from adobe.pdfservices.operation.pdfjobs.jobs.export_pdf_job import ExportPDFJob\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_params import ExportPDFParams\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_target_format import ExportPDFTargetFormat\n",
    "from adobe.pdfservices.operation.pdfjobs.result.export_pdf_result import ExportPDFResult\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# Initialize the logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class ExportPDFToDOCX:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.credentials = ServicePrincipalCredentials(\n",
    "            client_id=os.getenv('PDF_SERVICES_CLIENT_ID'),\n",
    "            client_secret=os.getenv('PDF_SERVICES_CLIENT_SECRET')\n",
    "        )\n",
    "        self.pdf_services = PDFServices(credentials=self.credentials)\n",
    "\n",
    "    def process(self, output_path):\n",
    "        try:\n",
    "            with open(self.pdf_path, 'rb') as file:\n",
    "                input_stream = file.read()\n",
    "\n",
    "            input_asset = self.pdf_services.upload(input_stream=input_stream, mime_type=PDFServicesMediaType.PDF)\n",
    "            export_pdf_params = ExportPDFParams(target_format=ExportPDFTargetFormat.DOCX)\n",
    "            export_pdf_job = ExportPDFJob(input_asset=input_asset, export_pdf_params=export_pdf_params)\n",
    "\n",
    "            location = self.pdf_services.submit(export_pdf_job)\n",
    "            pdf_services_response = self.pdf_services.get_job_result(location, ExportPDFResult)\n",
    "\n",
    "            result_asset: CloudAsset = pdf_services_response.get_result().get_asset()\n",
    "            stream_asset: StreamAsset = self.pdf_services.get_content(result_asset)\n",
    "\n",
    "            with open(output_path, \"wb\") as file:\n",
    "                file.write(stream_asset.get_input_stream())\n",
    "\n",
    "            return output_path\n",
    "\n",
    "        except ServiceApiException as e:\n",
    "            if \"CORRUPT_DOCUMENT\" in str(e):\n",
    "                logging.error(f\"The input PDF file appears to be corrupted: {e}\")\n",
    "                return \"CORRUPT_DOCUMENT\"\n",
    "            else:\n",
    "                logging.exception(f'Service API Exception encountered while converting PDF: {e}')\n",
    "                return None\n",
    "        except (ServiceUsageException, SdkException) as e:\n",
    "            logging.exception(f'Exception encountered while converting PDF: {e}')\n",
    "            return None\n",
    "\n",
    "def improve_text_with_bert(text):\n",
    "    if not text.strip():\n",
    "        return \"The extracted text is empty. Please check the input PDF file.\"\n",
    "\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    model = BertForMaskedLM.from_pretrained(model_name)\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "    fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "    sentences = text.split('.')\n",
    "    improved_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer.tokenize(sentence)\n",
    "        \n",
    "        if not tokens:\n",
    "            continue\n",
    "        \n",
    "        num_masks = max(1, int(0.15 * len(tokens)))\n",
    "        masked_indices = torch.randint(0, len(tokens), (num_masks,))\n",
    "        for idx in masked_indices:\n",
    "            tokens[idx] = \"[MASK]\"\n",
    "        \n",
    "        masked_sentence = tokenizer.convert_tokens_to_string(tokens)\n",
    "        \n",
    "        results = fill_mask(masked_sentence)\n",
    "        \n",
    "        for result in results:\n",
    "            if isinstance(result, dict) and 'token_str' in result:\n",
    "                masked_sentence = masked_sentence.replace(\"[MASK]\", result['token_str'], 1)\n",
    "            elif isinstance(result, list) and len(result) > 0 and 'token_str' in result[0]:\n",
    "                masked_sentence = masked_sentence.replace(\"[MASK]\", result[0]['token_str'], 1)\n",
    "        \n",
    "        improved_sentences.append(masked_sentence)\n",
    "\n",
    "    improved_text = '. '.join(improved_sentences)\n",
    "\n",
    "    return improved_text\n",
    "\n",
    "def fix_spelling_and_grammar(text):\n",
    "    if not text.strip():\n",
    "        return \"The input text is empty. Unable to perform spelling and grammar check.\"\n",
    "\n",
    "    tool = language_tool_python.LanguageTool('en-US')\n",
    "    corrected_text = tool.correct(text)\n",
    "    return corrected_text\n",
    "\n",
    "def process_pdf(pdf_file):\n",
    "    try:\n",
    "        # Create necessary directories\n",
    "        os.makedirs('adobe_output', exist_ok=True)\n",
    "        os.makedirs('final_output', exist_ok=True)\n",
    "\n",
    "        # Save uploaded PDF\n",
    "        pdf_path = os.path.join('adobe_output', 'input.pdf')\n",
    "        with open(pdf_path, 'wb') as f:\n",
    "            f.write(pdf_file if isinstance(pdf_file, bytes) else pdf_file.read())\n",
    "\n",
    "        # Convert PDF to DOCX using Adobe\n",
    "        exporter = ExportPDFToDOCX(pdf_path)\n",
    "        docx_path = os.path.join('adobe_output', 'output.docx')\n",
    "        docx_file = exporter.process(docx_path)\n",
    "\n",
    "        if docx_file is None:\n",
    "            return \"Error occurred during PDF to DOCX conversion.\"\n",
    "        elif docx_file == \"CORRUPT_DOCUMENT\":\n",
    "            return \"The uploaded PDF file appears to be corrupted. Please check the file and try again.\"\n",
    "\n",
    "        # Extract text from DOCX\n",
    "        text = docx2txt.process(docx_file)\n",
    "\n",
    "        if not text.strip():\n",
    "            return \"The extracted text is empty. Please check the input PDF file.\"\n",
    "\n",
    "        # Improve text using BERT\n",
    "        try:\n",
    "            improved_text = improve_text_with_bert(text)\n",
    "        except Exception as e:\n",
    "            logging.exception(f\"Error in BERT processing: {e}\")\n",
    "            improved_text = text\n",
    "\n",
    "        # Fix spelling and grammar\n",
    "        corrected_text = fix_spelling_and_grammar(improved_text)\n",
    "\n",
    "        # Save final output\n",
    "        final_output_path = os.path.join('final_output', 'processed_output.txt')\n",
    "        with open(final_output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(corrected_text)\n",
    "\n",
    "        return corrected_text\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"Error processing PDF: {e}\")\n",
    "        return f\"An error occurred while processing the PDF: {str(e)}\"\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_pdf,\n",
    "    inputs=gr.File(label=\"Upload PDF\", type=\"binary\"),\n",
    "    outputs=gr.Textbox(label=\"Processed Text\"),\n",
    "    title=\"PDF Cleaner, Improver, and Formatter\",\n",
    "    description=\"Upload a PDF file to convert it to a formatted text document with improved readability and corrected spelling/grammar.\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7879/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7879/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7879\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7879/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started submitting EXPORT_PDF job\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished polling for status\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting content\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting content\n",
      "C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596abe0c36004239b015ce8b78b9bf6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9925587f3403421384784fb62707494e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6886198df7db402692b47de582748755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7cbf9308f542fbb73224e1d95e41b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71bd3915f1c446d08c4e53b0cdce5af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (15409 > 1024). Running this sequence through the model will result in indexing errors\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "ERROR:root:Error processing PDF: index out of range in self\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\austi\\AppData\\Local\\Temp\\ipykernel_26020\\3347937394.py\", line 177, in process_pdf\n",
      "    final_text = process_with_gpt2(corrected_text, prompt)\n",
      "  File \"C:\\Users\\austi\\AppData\\Local\\Temp\\ipykernel_26020\\3347937394.py\", line 129, in process_with_gpt2\n",
      "    output = model.generate(input_ids, max_length=len(input_ids[0]) + 100, num_return_sequences=1, no_repeat_ngram_size=2)\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation_utils.py\", line 1490, in generate\n",
      "    return self.greedy_search(\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation_utils.py\", line 2233, in greedy_search\n",
      "    outputs = self(\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\", line 1046, in forward\n",
      "    transformer_outputs = self.transformer(\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\", line 833, in forward\n",
      "    position_embeds = self.wpe(position_ids)\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\sparse.py\", line 160, in forward\n",
      "    return F.embedding(\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\functional.py\", line 2210, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "IndexError: index out of range in self\n"
     ]
    }
   ],
   "source": [
    "####gpt2 local model###\n",
    "import gradio as gr\n",
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForMaskedLM, pipeline, GPT2LMHeadModel, GPT2Tokenizer\n",
    "import language_tool_python\n",
    "import docx2txt\n",
    "\n",
    "from adobe.pdfservices.operation.auth.service_principal_credentials import ServicePrincipalCredentials\n",
    "from adobe.pdfservices.operation.exception.exceptions import ServiceApiException, ServiceUsageException, SdkException\n",
    "from adobe.pdfservices.operation.io.cloud_asset import CloudAsset\n",
    "from adobe.pdfservices.operation.io.stream_asset import StreamAsset\n",
    "from adobe.pdfservices.operation.pdf_services import PDFServices\n",
    "from adobe.pdfservices.operation.pdf_services_media_type import PDFServicesMediaType\n",
    "from adobe.pdfservices.operation.pdfjobs.jobs.export_pdf_job import ExportPDFJob\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_params import ExportPDFParams\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_target_format import ExportPDFTargetFormat\n",
    "from adobe.pdfservices.operation.pdfjobs.result.export_pdf_result import ExportPDFResult\n",
    "\n",
    "# Initialize the logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class ExportPDFToDOCX:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.credentials = ServicePrincipalCredentials(\n",
    "            client_id=os.getenv('PDF_SERVICES_CLIENT_ID'),\n",
    "            client_secret=os.getenv('PDF_SERVICES_CLIENT_SECRET')\n",
    "        )\n",
    "        self.pdf_services = PDFServices(credentials=self.credentials)\n",
    "\n",
    "    def process(self, output_path):\n",
    "        try:\n",
    "            with open(self.pdf_path, 'rb') as file:\n",
    "                input_stream = file.read()\n",
    "\n",
    "            input_asset = self.pdf_services.upload(input_stream=input_stream, mime_type=PDFServicesMediaType.PDF)\n",
    "            export_pdf_params = ExportPDFParams(target_format=ExportPDFTargetFormat.DOCX)\n",
    "            export_pdf_job = ExportPDFJob(input_asset=input_asset, export_pdf_params=export_pdf_params)\n",
    "\n",
    "            location = self.pdf_services.submit(export_pdf_job)\n",
    "            pdf_services_response = self.pdf_services.get_job_result(location, ExportPDFResult)\n",
    "\n",
    "            result_asset: CloudAsset = pdf_services_response.get_result().get_asset()\n",
    "            stream_asset: StreamAsset = self.pdf_services.get_content(result_asset)\n",
    "\n",
    "            with open(output_path, \"wb\") as file:\n",
    "                file.write(stream_asset.get_input_stream())\n",
    "\n",
    "            return output_path\n",
    "\n",
    "        except ServiceApiException as e:\n",
    "            if \"CORRUPT_DOCUMENT\" in str(e):\n",
    "                logging.error(f\"The input PDF file appears to be corrupted: {e}\")\n",
    "                return \"CORRUPT_DOCUMENT\"\n",
    "            else:\n",
    "                logging.exception(f'Service API Exception encountered while converting PDF: {e}')\n",
    "                return None\n",
    "        except (ServiceUsageException, SdkException) as e:\n",
    "            logging.exception(f'Exception encountered while converting PDF: {e}')\n",
    "            return None\n",
    "\n",
    "def improve_text_with_bert(text):\n",
    "    if not text.strip():\n",
    "        return \"The extracted text is empty. Please check the input PDF file.\"\n",
    "\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    model = BertForMaskedLM.from_pretrained(model_name)\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "    fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "    sentences = text.split('.')\n",
    "    improved_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer.tokenize(sentence)\n",
    "        \n",
    "        if not tokens:\n",
    "            continue\n",
    "        \n",
    "        num_masks = max(1, int(0.15 * len(tokens)))\n",
    "        masked_indices = torch.randint(0, len(tokens), (num_masks,))\n",
    "        for idx in masked_indices:\n",
    "            tokens[idx] = \"[MASK]\"\n",
    "        \n",
    "        masked_sentence = tokenizer.convert_tokens_to_string(tokens)\n",
    "        \n",
    "        results = fill_mask(masked_sentence)\n",
    "        \n",
    "        for result in results:\n",
    "            if isinstance(result, dict) and 'token_str' in result:\n",
    "                masked_sentence = masked_sentence.replace(\"[MASK]\", result['token_str'], 1)\n",
    "            elif isinstance(result, list) and len(result) > 0 and 'token_str' in result[0]:\n",
    "                masked_sentence = masked_sentence.replace(\"[MASK]\", result[0]['token_str'], 1)\n",
    "        \n",
    "        improved_sentences.append(masked_sentence)\n",
    "\n",
    "    improved_text = '. '.join(improved_sentences)\n",
    "\n",
    "    return improved_text\n",
    "\n",
    "def fix_spelling_and_grammar(text):\n",
    "    if not text.strip():\n",
    "        return \"The input text is empty. Unable to perform spelling and grammar check.\"\n",
    "\n",
    "    tool = language_tool_python.LanguageTool('en-US')\n",
    "    corrected_text = tool.correct(text)\n",
    "    return corrected_text\n",
    "\n",
    "def generate_few_shot_prompt(examples, task_description):\n",
    "    prompt = f\"{task_description}\\n\\nExamples:\\n\"\n",
    "    for i, example in enumerate(examples, 1):\n",
    "        prompt += f\"Example {i}:\\nInput: {example['input']}\\nOutput: {example['output']}\\n\\n\"\n",
    "    prompt += \"Now, please process the following text:\\n\"\n",
    "    return prompt\n",
    "\n",
    "def process_with_gpt2(text, prompt):\n",
    "    model_name = \"gpt2-medium\"  # You can change this to a larger model if needed\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "    full_prompt = prompt + text\n",
    "    input_ids = tokenizer.encode(full_prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate output\n",
    "    output = model.generate(input_ids, max_length=len(input_ids[0]) + 100, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "    \n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract only the newly generated part\n",
    "    return generated_text[len(full_prompt):].strip()\n",
    "\n",
    "def process_pdf(pdf_file, examples, task_description):\n",
    "    try:\n",
    "        # Create necessary directories\n",
    "        os.makedirs('adobe_output', exist_ok=True)\n",
    "        os.makedirs('final_output', exist_ok=True)\n",
    "\n",
    "        # Save uploaded PDF\n",
    "        pdf_path = os.path.join('adobe_output', 'input.pdf')\n",
    "        with open(pdf_path, 'wb') as f:\n",
    "            f.write(pdf_file if isinstance(pdf_file, bytes) else pdf_file.read())\n",
    "\n",
    "        # Convert PDF to DOCX using Adobe\n",
    "        exporter = ExportPDFToDOCX(pdf_path)\n",
    "        docx_path = os.path.join('adobe_output', 'output.docx')\n",
    "        docx_file = exporter.process(docx_path)\n",
    "\n",
    "        if docx_file is None:\n",
    "            return \"Error occurred during PDF to DOCX conversion.\"\n",
    "        elif docx_file == \"CORRUPT_DOCUMENT\":\n",
    "            return \"The uploaded PDF file appears to be corrupted. Please check the file and try again.\"\n",
    "\n",
    "        # Extract text from DOCX\n",
    "        text = docx2txt.process(docx_file)\n",
    "\n",
    "        if not text.strip():\n",
    "            return \"The extracted text is empty. Please check the input PDF file.\"\n",
    "\n",
    "        # Improve text using BERT\n",
    "        try:\n",
    "            improved_text = improve_text_with_bert(text)\n",
    "        except Exception as e:\n",
    "            logging.exception(f\"Error in BERT processing: {e}\")\n",
    "            improved_text = text\n",
    "\n",
    "        # Fix spelling and grammar\n",
    "        corrected_text = fix_spelling_and_grammar(improved_text)\n",
    "\n",
    "        # Generate few-shot prompt\n",
    "        prompt = generate_few_shot_prompt(examples, task_description)\n",
    "\n",
    "        # Process with GPT-2\n",
    "        final_text = process_with_gpt2(corrected_text, prompt)\n",
    "\n",
    "        # Save final output\n",
    "        final_output_path = os.path.join('final_output', 'processed_output.txt')\n",
    "        with open(final_output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(final_text)\n",
    "\n",
    "        return final_text\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"Error processing PDF: {e}\")\n",
    "        return f\"An error occurred while processing the PDF: {str(e)}\"\n",
    "\n",
    "def process_with_examples(pdf_file, example1_input, example1_output, example2_input, example2_output, task_description):\n",
    "    examples = [\n",
    "        {\"input\": example1_input, \"output\": example1_output},\n",
    "        {\"input\": example2_input, \"output\": example2_output}\n",
    "    ]\n",
    "    return process_pdf(pdf_file, examples, task_description)\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_with_examples,\n",
    "    inputs=[\n",
    "        gr.File(label=\"Upload PDF\", type=\"binary\"),\n",
    "        gr.Textbox(label=\"Example 1 Input\"),\n",
    "        gr.Textbox(label=\"Example 1 Output\"),\n",
    "        gr.Textbox(label=\"Example 2 Input\"),\n",
    "        gr.Textbox(label=\"Example 2 Output\"),\n",
    "        gr.Textbox(label=\"Task Description\", \n",
    "                   placeholder=\"e.g., 'Improve the formatting and clarity of the following legal document:'\")\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Processed Text\"),\n",
    "    title=\"PDF Cleaner, Improver, and Formatter with Few-Shot Learning\",\n",
    "    description=\"Upload a PDF file and provide examples to guide the processing. The document will be converted, improved, and formatted based on your inputs.\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7882/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7882/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7882\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7882/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started submitting EXPORT_PDF job\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished polling for status\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting content\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting content\n",
      "C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:openai:error_code=rate_limit_exceeded error_message='Request too large for gpt-4 in organization org-StNcD0mXFRdWnl1IFhLonLQi on tokens per min (TPM): Limit 10000, Requested 15571. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "ERROR:root:Error in GPT-4 processing: Request too large for gpt-4 in organization org-StNcD0mXFRdWnl1IFhLonLQi on tokens per min (TPM): Limit 10000, Requested 15571. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\austi\\AppData\\Local\\Temp\\ipykernel_26020\\2701643328.py\", line 125, in process_with_gpt4\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_requestor.py\", line 226, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_requestor.py\", line 619, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_requestor.py\", line 679, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Request too large for gpt-4 in organization org-StNcD0mXFRdWnl1IFhLonLQi on tokens per min (TPM): Limit 10000, Requested 15571. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.\n"
     ]
    }
   ],
   "source": [
    "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started uploading asset\n",
    "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished uploading asset\n",
    "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started submitting EXPORT_PDF job\n",
    "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting job result\n",
    "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished polling for status\n",
    "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting job result\n",
    "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting content\n",
    "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting content\n",
    "C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
    "  warnings.warn(\n",
    "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
    "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
    "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
    "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.weight']\n",
    "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
    "INFO:openai:error_code=rate_limit_exceeded error_message='Request too large for gpt-4 in organization org-StNcD0mXFRdWnl1IFhLonLQi on tokens per min (TPM): Limit 10000, Requested 15571. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
    "ERROR:root:Error in GPT-4 processing: Request too large for gpt-4 in organization org-StNcD0mXFRdWnl1IFhLonLQi on tokens per min (TPM): Limit 10000, Requested 15571. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
    "Traceback (most recent call last):\n",
    "  File \"C:\\Users\\austi\\AppData\\Local\\Temp\\ipykernel_26020\\2701643328.py\", line 125, in process_with_gpt4\n",
    "    response = openai.ChatCompletion.create(\n",
    "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
    "    return super().create(*args, **kwargs)\n",
    "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 153, in create\n",
    "    response, _, api_key = requestor.request(\n",
    "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_requestor.py\", line 226, in request\n",
    "    resp, got_stream = self._interpret_response(result, stream)\n",
    "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_requestor.py\", line 619, in _interpret_response\n",
    "    self._interpret_response_line(\n",
    "  File \"C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\api_requestor.py\", line 679, in _interpret_response_line\n",
    "    raise self.handle_error_response(\n",
    "openai.error.RateLimitError: Request too large for gpt-4 in organization org-StNcD0mXFRdWnl1IFhLonLQi on tokens per min (TPM): Limit 10000, Requested 15571. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7886/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7886/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7886\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7886/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished uploading asset\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started submitting EXPORT_PDF job\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished polling for status\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting job result\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Started getting content\n",
      "INFO:adobe.pdfservices.operation.internal.pdf_services_helper:Finished getting content\n",
      "C:\\Users\\austi\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "import torch\n",
    "import time\n",
    "from transformers import BertTokenizerFast, BertForMaskedLM, pipeline\n",
    "import language_tool_python\n",
    "import docx2txt\n",
    "import openai\n",
    "\n",
    "from adobe.pdfservices.operation.auth.service_principal_credentials import ServicePrincipalCredentials\n",
    "from adobe.pdfservices.operation.exception.exceptions import ServiceApiException, ServiceUsageException, SdkException\n",
    "from adobe.pdfservices.operation.io.cloud_asset import CloudAsset\n",
    "from adobe.pdfservices.operation.io.stream_asset import StreamAsset\n",
    "from adobe.pdfservices.operation.pdf_services import PDFServices\n",
    "from adobe.pdfservices.operation.pdf_services_media_type import PDFServicesMediaType\n",
    "from adobe.pdfservices.operation.pdfjobs.jobs.export_pdf_job import ExportPDFJob\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_params import ExportPDFParams\n",
    "from adobe.pdfservices.operation.pdfjobs.params.export_pdf.export_pdf_target_format import ExportPDFTargetFormat\n",
    "from adobe.pdfservices.operation.pdfjobs.result.export_pdf_result import ExportPDFResult\n",
    "\n",
    "# Initialize the logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Set up OpenAI API key\n",
    "openai.api_key = \"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\"\n",
    "class ExportPDFToDOCX:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.credentials = ServicePrincipalCredentials(\n",
    "            client_id=os.getenv('PDF_SERVICES_CLIENT_ID'),\n",
    "            client_secret=os.getenv('PDF_SERVICES_CLIENT_SECRET')\n",
    "        )\n",
    "        self.pdf_services = PDFServices(credentials=self.credentials)\n",
    "\n",
    "    def process(self, output_path):\n",
    "        try:\n",
    "            with open(self.pdf_path, 'rb') as file:\n",
    "                input_stream = file.read()\n",
    "\n",
    "            input_asset = self.pdf_services.upload(input_stream=input_stream, mime_type=PDFServicesMediaType.PDF)\n",
    "            export_pdf_params = ExportPDFParams(target_format=ExportPDFTargetFormat.DOCX)\n",
    "            export_pdf_job = ExportPDFJob(input_asset=input_asset, export_pdf_params=export_pdf_params)\n",
    "\n",
    "            location = self.pdf_services.submit(export_pdf_job)\n",
    "            pdf_services_response = self.pdf_services.get_job_result(location, ExportPDFResult)\n",
    "\n",
    "            result_asset: CloudAsset = pdf_services_response.get_result().get_asset()\n",
    "            stream_asset: StreamAsset = self.pdf_services.get_content(result_asset)\n",
    "\n",
    "            with open(output_path, \"wb\") as file:\n",
    "                file.write(stream_asset.get_input_stream())\n",
    "\n",
    "            return output_path\n",
    "\n",
    "        except ServiceApiException as e:\n",
    "            if \"CORRUPT_DOCUMENT\" in str(e):\n",
    "                logging.error(f\"The input PDF file appears to be corrupted: {e}\")\n",
    "                return \"CORRUPT_DOCUMENT\"\n",
    "            else:\n",
    "                logging.exception(f'Service API Exception encountered while converting PDF: {e}')\n",
    "                return None\n",
    "        except (ServiceUsageException, SdkException) as e:\n",
    "            logging.exception(f'Exception encountered while converting PDF: {e}')\n",
    "            return None\n",
    "\n",
    "def improve_text_with_bert(text):\n",
    "    if not text.strip():\n",
    "        return \"The extracted text is empty. Please check the input PDF file.\"\n",
    "\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    model = BertForMaskedLM.from_pretrained(model_name)\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "    fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "    sentences = text.split('.')\n",
    "    improved_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer.tokenize(sentence)\n",
    "        \n",
    "        if not tokens:\n",
    "            continue\n",
    "        \n",
    "        num_masks = max(1, int(0.15 * len(tokens)))\n",
    "        masked_indices = torch.randint(0, len(tokens), (num_masks,))\n",
    "        for idx in masked_indices:\n",
    "            tokens[idx] = \"[MASK]\"\n",
    "        \n",
    "        masked_sentence = tokenizer.convert_tokens_to_string(tokens)\n",
    "        \n",
    "        results = fill_mask(masked_sentence)\n",
    "        \n",
    "        for result in results:\n",
    "            if isinstance(result, dict) and 'token_str' in result:\n",
    "                masked_sentence = masked_sentence.replace(\"[MASK]\", result['token_str'], 1)\n",
    "            elif isinstance(result, list) and len(result) > 0 and 'token_str' in result[0]:\n",
    "                masked_sentence = masked_sentence.replace(\"[MASK]\", result[0]['token_str'], 1)\n",
    "        \n",
    "        improved_sentences.append(masked_sentence)\n",
    "\n",
    "    improved_text = '. '.join(improved_sentences)\n",
    "\n",
    "    return improved_text\n",
    "\n",
    "def fix_spelling_and_grammar(text):\n",
    "    if not text.strip():\n",
    "        return \"The input text is empty. Unable to perform spelling and grammar check.\"\n",
    "\n",
    "    tool = language_tool_python.LanguageTool('en-US')\n",
    "    corrected_text = tool.correct(text)\n",
    "    return corrected_text\n",
    "\n",
    "def generate_few_shot_prompt(examples, task_description):\n",
    "    prompt = f\"{task_description}\\n\\nExamples:\\n\"\n",
    "    for i, example in enumerate(examples, 1):\n",
    "        prompt += f\"Example {i}:\\nInput: {example['input']}\\nOutput: {example['output']}\\n\\n\"\n",
    "    prompt += \"Now, please process the following text:\\n\"\n",
    "    return prompt\n",
    "\n",
    "def estimate_tokens(text):\n",
    "    return max(1, len(text.split()))  # Ensure we never return 0\n",
    "\n",
    "def process_with_gpt4(text, prompt):\n",
    "    try:\n",
    "        max_tokens = 4000  # Maximum tokens allowed per request\n",
    "        estimated_tokens = estimate_tokens(text)\n",
    "        text_length = max(1, len(text))  # Ensure we never divide by zero\n",
    "        \n",
    "        # Calculate chunk size, ensuring it's at least 1 and at most the text length\n",
    "        chunk_size = max(1, min(text_length, max_tokens // max(1, (estimated_tokens // text_length))))\n",
    "        \n",
    "        chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "        \n",
    "        processed_chunks = []\n",
    "        \n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunk_prompt = f\"{prompt}\\n\\nPart {i+1} of {len(chunks)}:\\n{chunk}\"\n",
    "            \n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that processes and improves documents based on given examples and instructions.\"},\n",
    "                    {\"role\": \"user\", \"content\": chunk_prompt}\n",
    "                ],\n",
    "                max_tokens=1000,  # Adjust as needed\n",
    "                n=1,\n",
    "                temperature=0.7,\n",
    "            )\n",
    "            \n",
    "            processed_chunk = response.choices[0].message['content'].strip()\n",
    "            processed_chunks.append(processed_chunk)\n",
    "            \n",
    "            # Sleep for a short time to avoid hitting rate limits\n",
    "            time.sleep(20)  # Adjust this value based on your API rate limits\n",
    "        \n",
    "        return \" \".join(processed_chunks)\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"Error in GPT-4 processing: {e}\")\n",
    "        return f\"Error occurred during GPT-4 processing: {str(e)}\"\n",
    "\n",
    "def process_pdf(pdf_file, examples, task_description):\n",
    "    try:\n",
    "        # Create necessary directories\n",
    "        os.makedirs('adobe_output', exist_ok=True)\n",
    "        os.makedirs('final_output', exist_ok=True)\n",
    "\n",
    "        # Save uploaded PDF\n",
    "        pdf_path = os.path.join('adobe_output', 'input.pdf')\n",
    "        with open(pdf_path, 'wb') as f:\n",
    "            f.write(pdf_file if isinstance(pdf_file, bytes) else pdf_file.read())\n",
    "\n",
    "        # Convert PDF to DOCX using Adobe\n",
    "        exporter = ExportPDFToDOCX(pdf_path)\n",
    "        docx_path = os.path.join('adobe_output', 'output.docx')\n",
    "        docx_file = exporter.process(docx_path)\n",
    "\n",
    "        if docx_file is None:\n",
    "            return \"Error occurred during PDF to DOCX conversion.\"\n",
    "        elif docx_file == \"CORRUPT_DOCUMENT\":\n",
    "            return \"The uploaded PDF file appears to be corrupted. Please check the file and try again.\"\n",
    "\n",
    "        # Extract text from DOCX\n",
    "        text = docx2txt.process(docx_file)\n",
    "\n",
    "        if not text.strip():\n",
    "            return \"The extracted text is empty. Please check the input PDF file.\"\n",
    "\n",
    "        # Improve text using BERT\n",
    "        try:\n",
    "            improved_text = improve_text_with_bert(text)\n",
    "        except Exception as e:\n",
    "            logging.exception(f\"Error in BERT processing: {e}\")\n",
    "            improved_text = text\n",
    "\n",
    "        # Fix spelling and grammar\n",
    "        corrected_text = fix_spelling_and_grammar(improved_text)\n",
    "\n",
    "        # Generate few-shot prompt\n",
    "        prompt = generate_few_shot_prompt(examples, task_description)\n",
    "\n",
    "        # Process with GPT-4\n",
    "        final_text = process_with_gpt4(corrected_text, prompt)\n",
    "\n",
    "        # Save final output\n",
    "        final_output_path = os.path.join('final_output', 'processed_output.txt')\n",
    "        with open(final_output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(final_text)\n",
    "\n",
    "        return final_text\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"Error processing PDF: {e}\")\n",
    "        return f\"An error occurred while processing the PDF: {str(e)}\"\n",
    "\n",
    "def process_with_examples(pdf_file, example1_input, example1_output, example2_input, example2_output, task_description):\n",
    "    examples = [\n",
    "        {\"input\": example1_input, \"output\": example1_output},\n",
    "        {\"input\": example2_input, \"output\": example2_output}\n",
    "    ]\n",
    "    return process_pdf(pdf_file, examples, task_description)\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_with_examples,\n",
    "    inputs=[\n",
    "        gr.File(label=\"Upload PDF\", type=\"binary\"),\n",
    "        gr.Textbox(label=\"Example 1 Input\"),\n",
    "        gr.Textbox(label=\"Example 1 Output\"),\n",
    "        gr.Textbox(label=\"Example 2 Input\"),\n",
    "        gr.Textbox(label=\"Example 2 Output\"),\n",
    "        gr.Textbox(label=\"Task Description\", \n",
    "                   placeholder=\"e.g., 'Improve the formatting and clarity of the following legal document:'\")\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Processed Text\"),\n",
    "    title=\"PDF Cleaner, Improver, and Formatter with GPT-4\",\n",
    "    description=\"Upload a PDF file and provide examples to guide the processing. The document will be converted, improved, and formatted using GPT-4 based on your inputs.\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
